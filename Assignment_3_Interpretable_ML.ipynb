{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNR77kCQiMYyKFvSstOGReQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calicartels/Interpretable_ML/blob/main/Assignment_3_Interpretable_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygam\n",
        "!git clone https://github.com/calicartels/Interpretable_ML.git"
      ],
      "metadata": {
        "id": "AML4NENmTuf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Importing Libraries and Datasets"
      ],
      "metadata": {
        "id": "FXTcHpF-TpQB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rK08iYjPiFz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "from pygam import LogisticGAM, s\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import scipy.stats as stats\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "igdyPJdoSIRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. EDA"
      ],
      "metadata": {
        "id": "3LscVHctTxrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting some basic information about the dataset, by checking the column types and count\n",
        "df.info()"
      ],
      "metadata": {
        "id": "-QZjQRaATmpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describing the variables across various statistical measures\n",
        "df.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "bEP8XomeSR_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doing another round of this, but without categorical variables because the last output was too verbose\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "Td-Jy8h3U1K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicate entries in the dataset\n",
        "df.duplicated().sum()\n",
        "\n",
        "# result : no duplicate values"
      ],
      "metadata": {
        "id": "wJv2BKIzT2tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for null values in the dataset\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "# result: no null values"
      ],
      "metadata": {
        "id": "3nRu6Zd-UAPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Visualization"
      ],
      "metadata": {
        "id": "JQeU-L1-X8Uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Basic Viz"
      ],
      "metadata": {
        "id": "hWtoJiZjdxRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Churn distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data=df, x='Churn', palette=\"Accent\")\n",
        "plt.title('Churn Distribution')\n",
        "plt.show()\n",
        "\n",
        "# result : pretty straightforward, a lot of people stay with the company, but a considerable amount also leave it for a competitor."
      ],
      "metadata": {
        "id": "dLZm_ax3XmJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot pie chart\n",
        "\n",
        "\n",
        "palette = sns.color_palette(\"Set2\")\n",
        "gb = df.groupby(\"Churn\").agg({\"Churn\": \"count\"})\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(gb[\"Churn\"], labels=gb.index, autopct=\"%1.2f%%\", colors=palette)\n",
        "plt.title(\"Percentage of Churned Customers\", fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# result : visualizing in percentage"
      ],
      "metadata": {
        "id": "VGJkcpMolIc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plot for tenure, MonthlyCharges, and TotalCharges with respect to Churn\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Tenure\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.boxplot(data=df, x='Churn', y='tenure')\n",
        "plt.title('Tenure vs Churn')\n",
        "\n",
        "# MonthlyCharges\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.boxplot(data=df, x='Churn', y='MonthlyCharges')\n",
        "plt.title('Monthly Charges vs Churn')\n",
        "\n",
        "# TotalCharges\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.boxplot(data=df, x='Churn', y='TotalCharges')\n",
        "plt.title('Total Charges vs Churn')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gNyOXgxYYbEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "result :\n",
        "\n",
        " 1. From the first plot, I can see that the those who churn do it within the first 30 or so months, excluding a couple of outliers.\n",
        "  It's interesting to see an overlap betweeen the first quartile of the \"No churn\" and the third quartile of the \"Yes Churn\" column.\n",
        " The company should definitely look into why there are difference between people who stay for the same amount of time.\n",
        "\n",
        " 2. From the second plot we can see that people on average being charged more tend to leave the company. Might be worth to check the socio-economic\n",
        "  and provide targeted offers.\n",
        "\n",
        " 3. The third plot as a lott of outliers in the \"Yes churn\" column, which is quite interesting. but on a very high level observation, the plot is pretty\n",
        "   self-explanatory in the sense that people who leave early have lower charges."
      ],
      "metadata": {
        "id": "Bmd0EkMBkyNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Encoding variables"
      ],
      "metadata": {
        "id": "YQluN30-tn2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 . Lets drop the customerID because it has no intrinsic value as such:\n",
        "df = df.drop('customerID', axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "n-pJQ80Kt4t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Label Encoding and One-Hot Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Converting 'TotalCharges' to numeric, coercing errors to NaN, then fill NaNs with 0\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce').fillna(0)\n",
        "\n",
        "# Converting 'Churn' to binary values (0 for 'No', 1 for 'Yes')\n",
        "df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})\n",
        "\n",
        "# Converting binary categorical features using Label Encoding\n",
        "binary_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
        "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "                   'StreamingTV', 'StreamingMovies', 'PaperlessBilling']\n",
        "\n",
        "for feature in binary_features:\n",
        "    df[feature] = label_encoder.fit_transform(df[feature])\n",
        "\n",
        "# Converting multi-class categorical features using One-Hot Encoding\n",
        "df = pd.get_dummies(df, columns=['InternetService', 'Contract', 'PaymentMethod'], drop_first=True)\n",
        "\n",
        "# 2. Normalization of numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "# Fit and transform the numerical features\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "print(df.info())\n",
        "print(\"\\nSample of normalized numerical features:\")\n",
        "print(df[numerical_features].head())"
      ],
      "metadata": {
        "id": "q3Fp5meRulYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I) Linear Regression"
      ],
      "metadata": {
        "id": "RN5O30bx3DGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 5 Feature Selection and Assumption Testing"
      ],
      "metadata": {
        "id": "HYfF2vBBsdxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Before we dive any deeper into the visualizations and checking the relationships, we should perform feature selection so that we dont redundantly work with all available variables"
      ],
      "metadata": {
        "id": "BlnHiqp1sY2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Lets start with a correlation analysis, with our target variable being \"churn\"\n",
        "\n",
        "corr_with_target = df.corr()['Churn'].sort_values(ascending=False)\n",
        "print(corr_with_target)\n",
        "\n"
      ],
      "metadata": {
        "id": "sWbH6k6jtCWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "correlation works by checking if the variables are directly or indirectly proportional to the target variable.\n",
        "\n",
        "In terms of this problem statement:\n",
        "\n",
        "* Positive Correlation: Values above 0 indicate a positive relationship. As these features increase, the likelihood of Churn increases.\n",
        "\n",
        "* Negative Correlation: Values below 0 indicate a negative relationship. As these features increase, the likelihood of Churn decreases.\n",
        "\n",
        "Some features show very low correlation with Churn:\n",
        "\n",
        "\t•\tgender (-0.009)\n",
        "\t•\tPhoneService (0.012)\n",
        "\t•\tMultipleLines (0.038)\n",
        "\n",
        "These features might not have a significant impact on churn based on this correlation analysis.\n",
        "\n",
        "\n",
        "Highly Correlated Features:\n",
        "\n",
        "\t•\tPositive: InternetService_Fiber optic, PaymentMethod_Electronic check\n",
        "\t•\tNegative: Contract_Two year, tenure\n",
        "\n",
        "These features are pretty important and directly influence the model."
      ],
      "metadata": {
        "id": "vBdXSSKPyVbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Linearity\n",
        "\n",
        "Linear regression models are based on the idea that there is a straight-line relationship between the independent variables  X1, X2, …, Xn  and the predicted value of the target variable  Y . This relationship is described by the equation:\n",
        "\n",
        " $$\\hat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + … + \\beta_n X_n $$\n",
        "\n",
        "In this equation, we assume:\n",
        "\tEach feature has a constant effect on the target variable.\n",
        "\tChanges in the features  X_i  result in proportional changes in the target.\n",
        "\n",
        "This straight-line (linear) assumption is crucial to how the model makes predictions. The coefficients represent the slope of the line and indicate the impact of each feature on the target variable.\n",
        "\n",
        "Therefore Linearity is assumed"
      ],
      "metadata": {
        "id": "7qDJT4hzvVbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2 Checking for Independence and Multicollinearity"
      ],
      "metadata": {
        "id": "BrDh7Xp7q0u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Lets proceed with a correlation matrix:\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr_matrix = df.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.show()\n",
        "\n",
        "# result: Shows a quick overview of the relationships between multiple variables all at once."
      ],
      "metadata": {
        "id": "yDfhLpFEtQJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this matrix above we can see that the features which are correlated to each other are:\n",
        "\n",
        "* Tenure and Total Charges\n",
        "* InternetService_No and Monthly Charges\n",
        "* InternetService_Fiber optic and MonthlyCharges\n",
        "* TotalCharges and MonthlyCharges\n",
        "* Contract_Two year and tenure\n",
        "\n",
        "and None of the features have a complete dependance on each other hence proving Independance"
      ],
      "metadata": {
        "id": "27yS8Z7NpXmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "`**before we move any further, the rest of the assumptions can be tested only after fitting the data into the model.**`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MMnoqpzXQPGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###6 Feature Selection using RFE, modelling and evaluation\n"
      ],
      "metadata": {
        "id": "kGJxk6fhSfwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X = df.drop(columns=['Churn'])  # Features\n",
        "y = df['Churn']  # Target variable\n",
        "\n",
        "# Spliting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a linear regression model\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Using RFE (Recursive Feature Elimination) to select the top n features:\n",
        "\n",
        "n_features_to_select = 13  # Choose the number of features to select,\n",
        "# I landed on 13 through a trial and error process and it preserved most of the accuracy.\n",
        "\n",
        "rfe = RFE(estimator=linear_model, n_features_to_select=n_features_to_select)\n",
        "\n",
        "# Fitting RFE on training data\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Getting the selected features (True for selected features, False for unselected)\n",
        "selected_features = rfe.support_\n",
        "\n",
        "# Listing of selected feature names\n",
        "pruned_features = X_train.columns[selected_features]\n",
        "print(\"Selected features:\", pruned_features)\n",
        "\n",
        "# Pruning the features based on the results\n",
        "X_train_pruned = X_train[pruned_features]\n",
        "X_test_pruned = X_test[pruned_features]\n",
        "\n",
        "# Fitting linear regression model with pruned features\n",
        "linear_model.fit(X_train_pruned, y_train)\n",
        "\n",
        "# Making predictions on the test set (regression output)\n",
        "y_pred_continuous = linear_model.predict(X_test_pruned)\n",
        "\n",
        "# Converting continuous predictions to binary (classification) using a threshold (0.5)\n",
        "y_pred = (y_pred_continuous >= 0.5).astype(int)\n",
        "\n",
        "# Evaluating the model with classification metrics\n",
        "f1_li = f1_score(y_test, y_pred)\n",
        "accuracy_li = accuracy_score(y_test, y_pred)\n",
        "precision_li = precision_score(y_test, y_pred)\n",
        "recall_li = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy_li}')\n",
        "print(f'Precision: {precision_li}')\n",
        "print(f'Recall: {recall_li}')\n",
        "print(f'F1 Score: {f1_li}')"
      ],
      "metadata": {
        "id": "hg1htAOp1-qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Take Aways**\n",
        "\n",
        "1. Accuracy (81.7%):\n",
        "\n",
        "\t•\tAverage, but honestly not necessarily reliable in this case. Accuracy can be misleading, since this is an imbalanced dataset (More customers stay than leave). Here it might mean that the model is predicting the customers who stay correctly while failing to capture the customers who churn.\n",
        "\n",
        "2. Precision (68.5%):\n",
        "\n",
        "\t•\tPrecision measures how many of the predicted “churns” are actually churners. It’s correct about 68.5% of the time. This is moderate, but not great for a churn prediction model.\n",
        "\n",
        "3. Recall (57.3%):\n",
        "\n",
        "\t•\tPoor, a recall of 57.3% means the model is missing over half of the actual churners, which is problematic because the goal of churn prediction is to identify those customers at risk of leaving.\n",
        "\n",
        "4. F1 Score (62.4%):\n",
        "\n",
        "\t•\tAt 62.4%, it suggests that the model has a moderate trade-off between precision and recall, but neither is particularly strong. Given that the F1 score is relatively low compared to accuracy, this indicates the model is having trouble balancing precision and recall."
      ],
      "metadata": {
        "id": "jOtyoUXhUOpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1 Model Coefficient analysis:\n",
        "\n"
      ],
      "metadata": {
        "id": "uTkoBU2ZI3gX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = linear_model.coef_\n",
        "\n",
        "import pandas as pd\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X_train_pruned.columns,\n",
        "    'Coefficient': coefficients\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "id": "ndDwYL-aI2j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.\tPositive Coefficients:\n",
        "\n",
        "•\tInternetService_Fiber optic (0.347202): Customers with Fiber optic internet service are associated with a higher likelihood of churn. This feature has the highest positive coefficient, indicating it’s a strong predictor of churn.\n",
        "\n",
        "•\tPhoneService (0.129168):\n",
        "\n",
        "Having phone service slightly increases the likelihood of churn, though the effect is relatively modest compared to other features.\n",
        "\n",
        "•\tPaymentMethod_Electronic check (0.077325):\n",
        "\n",
        "Using electronic check as a payment method is associated with a small increase in churn likelihood.\n",
        "\n",
        "•\tStreamingMovies (0.066541):\n",
        "\n",
        "Subscribing to streaming movies is positively related to churn, but the impact is small.\n",
        "\n",
        "•\tStreamingTV (0.055674):\n",
        "\n",
        "Similar to streaming movies, streaming TV has a slight positive effect on churn.\n",
        "\n",
        "•\tPaperlessBilling (0.047954):\n",
        "\n",
        "Opting for paperless billing has a small positive effect on churn.\n",
        "\n",
        "•\tMultipleLines (0.042442):\n",
        "\n",
        "Having multiple lines slightly increases the churn probability, but the effect is minimal.\n",
        "\n",
        "2.\tNegative Coefficients:\n",
        "\n",
        "\n",
        "•\ttenure (-0.044162):\n",
        "\n",
        "Longer tenure is associated with a slightly lower likelihood of churn. This is expected as customers who stay longer are generally less likely to churn.\n",
        "\n",
        "•\tContract_Two year (-0.093447):\n",
        "\n",
        "Having a two-year contract decreases the likelihood of churn more than a one-year contract, as customers with longer commitments are less likely to leave.\n",
        "\n",
        "•\tTotalCharges (-0.094997):\n",
        "\n",
        "Higher total charges are negatively associated with churn. This might indicate that customers who have spent more are less likely to leave.\n",
        "\n",
        "•\tContract_One year (-0.113600):\n",
        "\n",
        " A one-year contract reduces the likelihood of churn compared to having no contract.\n",
        "\n",
        "•\tMonthlyCharges (-0.196272):\n",
        "\n",
        "Higher monthly charges are strongly negatively associated with churn, suggesting that more expensive plans are less likely to result in churn.\n",
        "\n",
        "•\tInternetService_No (-0.423436):\n",
        "\n",
        "Not having internet service is strongly negatively associated with churn. This indicates that customers without internet service are significantly less likely to churn.\n"
      ],
      "metadata": {
        "id": "PLd1THX9Lf0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7  Testing Assumptions for Linear regression: (contd..)"
      ],
      "metadata": {
        "id": "CLtXy5dtfQnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.1 Homoscedasticity\n",
        "\n",
        "To test for homoscedasticity, we can you a Residuals vs. Fitted values plot. If the model is homoscedastic, the residuals will scatter randomly around zero with no visible pattern.\n"
      ],
      "metadata": {
        "id": "iLA3lNCwfcwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predictions for training data\n",
        "y_train_pred = linear_model.predict(X_train_pruned)\n",
        "\n",
        "# Residuals (errors) = actual values - predicted values\n",
        "residuals = y_train - y_train_pred\n",
        "\n",
        "# Plot Residuals vs. Fitted values\n",
        "plt.scatter(y_train_pred, residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Fitted values (Predicted)')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Fitted Values (Homoscedasticity Check)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P-nF1yX2Pwvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot shows us that we have a probelem with homoscedasticity.\n",
        "\n",
        "1. The residuals are not randomly scattered around the zero line. Instead, there's a clear downward trend as the fitted values increase.\n",
        "\n",
        "2. The spread of residuals is wider on the left side of the plot and narrows as you move to the right which is a sign of heteroscedasticity.\n",
        "\n",
        "3. The residuals are not symmetrically distributed above and below the zero line, especially for higher fitted values.\n",
        "\n",
        "4. The variance of residuals appears to decrease as the fitted values increase, which violates the assumption of constant variance.\n",
        "\n",
        "\n",
        "**We can try to fix this using weighted least squares**"
      ],
      "metadata": {
        "id": "uGiebvQXhrZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.2 Normality\n",
        "\n",
        "We can use the Q-Q plot to test for QQ plot and histogram of the residuals. A QQ plot compares the distribution of residuals with a normal distribution.\n",
        "\n",
        "Normality is essentially done to check if the residuals follow a normal distribution."
      ],
      "metadata": {
        "id": "febs9nvci7KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# QQ plot\n",
        "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "plt.title('QQ plot for residuals (Normality Check)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OBpHhnLyiulI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result : While the data isnt exactly normally distributed, we can find that there are outliers, since it doesnt follow the line completely."
      ],
      "metadata": {
        "id": "iA_dobkyqlWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.3 No Autocorrelation\n",
        "\n",
        "We can use something called the durbin-Watson test to determine whether there is anytype of autocorrelation or not.\n",
        "\n",
        "The values range between 0 and 4. A value close to 2 means no autocorrelation. Values closer to 0 indicate positive autocorrelation, and values closer to 4 indicate negative autocorrelation."
      ],
      "metadata": {
        "id": "SH8aiqv1tLz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dw = durbin_watson(residuals)\n",
        "print(f'Durbin-Watson statistic: {dw}')"
      ],
      "metadata": {
        "id": "Brev_3l1jIv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result: As expected, there are no autocorrelations between the residuals, and the test proves the same since it is closer to 2"
      ],
      "metadata": {
        "id": "84PUe0Opw0Xm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II) Logistic Regression"
      ],
      "metadata": {
        "id": "A6eVLw1f3Uru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets test the data on Logistic regression"
      ],
      "metadata": {
        "id": "B_CP4VB7-XFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define Features and Target variable\n",
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using LassoCV for feature selection\n",
        "lasso = LassoCV(cv=10).fit(X_train, y_train)\n",
        "\n",
        "# Select the features with non-zero coefficients from Lasso\n",
        "selected_features = np.where(lasso.coef_ != 0)[0]  # Indices of selected features\n",
        "pruned_features = X_train.columns[selected_features]\n",
        "\n",
        "print(\"Selected features:\", pruned_features)\n",
        "\n",
        "# Pruning the features based on the Lasso results\n",
        "X_train_pruned = X_train[pruned_features]\n",
        "X_test_pruned = X_test[pruned_features]\n",
        "\n",
        "# Now fitting Logistic Regression with pruned features\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "logistic_model.fit(X_train_pruned, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = logistic_model.predict(X_test_pruned)\n",
        "\n",
        "# Evaluating the model with classification metrics\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "id": "S1jsNYQUyzUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Takeaways**\n",
        "\n",
        "When compared to linear regression, the improvement in evaluation metrics is ever so small.\n",
        "\n",
        "One could say both these models perform almost the same."
      ],
      "metadata": {
        "id": "kiQv5YSPGTph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Checking coefficients of this logistic regression :"
      ],
      "metadata": {
        "id": "6Ij4Lap7InWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = logistic_model.coef_[0]\n",
        "\n",
        "import pandas as pd\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X_train_pruned.columns,\n",
        "    'Coefficient': coefficients\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "id": "BN3KJDEk-X5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tTotalCharges (0.654931):\n",
        "\n",
        "•\tHigher total charges are associated with a higher likelihood of customer churn. As total charges increase, the odds of churn increase.\n",
        "2.\tInternetService_Fiber optic (0.505281):\n",
        "\n",
        "•\tCustomers with fiber optic internet service are more likely to churn compared to those with other types of internet services.\n",
        "3.\tPaymentMethod_Electronic check (0.362013):\n",
        "\n",
        "•\tUsing an electronic check as the payment method is positively associated with churn. This suggests customers who use electronic checks are more likely to leave.\n",
        "4.\tPaperlessBilling (0.334962):\n",
        "\n",
        "•\tOpting for paperless billing is linked to a higher chance of churn.\n",
        "5.\tMonthlyCharges (0.273855):\n",
        "\n",
        "•\tHigher monthly charges correlate with an increased likelihood of churn.\n",
        "6.\tMultipleLines (0.097659):\n",
        "\n",
        "•\tHaving multiple lines is slightly positively associated with churn.\n",
        "\n",
        "7.\tStreamingMovies (0.083880):\n",
        "\n",
        "•\tSubscribing to streaming movies has a small positive effect on churn probability.\n",
        "\n",
        "8.\tSeniorCitizen (0.061601):\n",
        "\n",
        "•\tBeing a senior citizen is slightly associated with higher churn risk.\n",
        "\n",
        "9.\tStreamingTV (0.034202):\n",
        "\n",
        "•\tSubscribing to streaming TV has a minor positive impact on churn.\n",
        "\n",
        "Negative Coefficients:\n",
        "\n",
        "1.\tDeviceProtection (-0.046501):\n",
        "\n",
        "•\tHaving device protection is associated with a lower likelihood of churn. Customers with device protection are less likely to leave.\n",
        "2.\tgender (-0.051376):\n",
        "\n",
        "•\tThe gender feature has a small negative coefficient, suggesting a slight decrease in churn likelihood, but the effect is minimal.\n",
        "3.\tOnlineBackup (-0.123194):\n",
        "\n",
        "•\tSubscribing to online backup services is negatively associated with churn.\n",
        "4.\tDependents (-0.134017):\n",
        "\n",
        "•\tHaving dependents is associated with a lower likelihood of churn.\n",
        "5.\tTechSupport (-0.213062):\n",
        "\n",
        "•\tAccess to tech support is significantly negatively associated with churn, indicating that customers who receive tech support are less likely to leave.\n",
        "6.\tOnlineSecurity (-0.251430):\n",
        "\n",
        "•\tOnline security features reduce the likelihood of churn. Customers with online security are less likely to churn.\n",
        "7.\tContract_One year (-0.637173):\n",
        "\n",
        "•\tCustomers with a one-year contract are less likely to churn compared to those with other contract types.\n",
        "8.\tPhoneService (-0.737503):\n",
        "\n",
        "•\tHaving phone service is strongly negatively associated with churn. Customers with phone service are significantly less likely to leave.\n",
        "9.\ttenure (-1.356694):\n",
        "\n",
        "•\tLonger tenure strongly reduces the likelihood of churn. Customers who have been with the company longer are much less likely to leave.\n",
        "10.\tContract_Two year (-1.393828):\n",
        "\n",
        "•\tA two-year contract is strongly associated with a lower chance of churn compared to other contract types.\n"
      ],
      "metadata": {
        "id": "P6qwelTxKfKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### III) Generalized Additive Model (GAM)"
      ],
      "metadata": {
        "id": "w4jyKnQ8N973"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Features and Target variable\n",
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "# Spliting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Defining the GAM model with spline terms for each feature\n",
        "gam = LogisticGAM(s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) +\n",
        "                   s(10) + s(11) + s(12) + s(13) + s(14) + s(15) + s(16) + s(17) + s(18))\n",
        "\n",
        "# Fitting the GAM model\n",
        "gam.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set, using ndim because I ran into shape problems :/\n",
        "y_pred_prob = gam.predict_proba(X_test)\n",
        "if y_pred_prob.ndim == 2 and y_pred_prob.shape[1] > 1:\n",
        "    y_pred_prob = y_pred_prob[:, 1]  # Extract probability for the positive class\n",
        "else:\n",
        "    y_pred_prob = y_pred_prob  # Already represents the probability of the positive class\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "# Evaluating the model with classification metrics\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "id": "QVI1P2IJIs4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Analyzing the Coefficients for GAM:"
      ],
      "metadata": {
        "id": "HIuM4k0qQ1y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "print(gam.summary())\n",
        "\n"
      ],
      "metadata": {
        "id": "aHDNoASWO2Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inferences: (Even though the output says \"Please do not make inferences based on these values! \")\n",
        "\n",
        "\n",
        "Here's the breakdown with numbering:\n",
        "\n",
        "1. Model Fit:  \n",
        "   - The Log Likelihood is -2321.7622, measuring the fit of the model to the data. A higher (less negative) value indicates a better fit.\n",
        "   - The AIC is 4748.7704, used to compare models. Lower values indicate a better balance between fit and complexity.\n",
        "   - The Pseudo R-Squared is 0.288, meaning the model explains about 28.8% of the variability in the target (Churn). This suggests there’s room for improvement or unobserved factors affecting churn.\n",
        "\n",
        "2. Significance of Features:  \n",
        "   - Most features from s(4) to s(18) are highly significant (`***`), with p-values less than 0.001. These features have a strong impact on churn.\n",
        "   - s(1) is moderately significant (*), showing a weaker but noticeable relationship with churn.\n",
        "   - Non-significant features like s(0), s(2), and s(3) don't show a statistically significant impact on churn outcomes.\n",
        "\n",
        "3. Complexity of Features:  \n",
        "   - Features with high Effective Degrees of Freedom (EDoF), like s(4) and s(14), indicate complex, non-linear relationships with churn.\n",
        "   - Low EDoF values, such as for s(1), suggest simpler, more linear relationships.\n",
        "\n",
        "4. Feature Interpretation:  \n",
        "   - Focus on features with high significance (***) as they are key drivers of churn. These might include customer behaviors, service types, or contract details.\n",
        "   - Consider excluding or transforming non-significant features (s(0), s(2), s(3)) to simplify the model.\n",
        "\n",
        "5. Model Performance:  \n",
        "   - While the model provides insights into the factors affecting churn, the moderate Pseudo R-Squared suggests that performance could be improved, possibly by refining features or adding more relevant variables."
      ],
      "metadata": {
        "id": "do9_ZtcXRLWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verdict:\n",
        "\n",
        "The three models were explored and all of them have similar performance on the data. So, it becomes very specific to the use case:"
      ],
      "metadata": {
        "id": "3QuDlAdgUY0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Logistic Regression:\n",
        "\n",
        "•\tSuitability: Best suited for binary classification tasks like churn prediction.\n",
        "•\tPerformance: Generally performs well for straightforward data relationships.\n",
        "•\tInterpretability: Coefficients are easy to interpret, providing clear insights into how each feature affects churn probability.\n",
        "•\tBusiness Relevance: Helps in understanding which features most influence churn, making it easier to implement targeted strategies.\n",
        "\n",
        "2. Generalized Additive Models (GAMs):\n",
        "\n",
        "•\tSuitability: Good for capturing non-linear relationships between features and churn.\n",
        "•\tPerformance: Can outperform logistic regression if there are complex interactions in the data.\n",
        "•\tInterpretability: More complex to interpret, but offers a deeper understanding of feature impacts.\n",
        "•\tBusiness Relevance: Provides nuanced insights but may be harder for business stakeholders to grasp and act upon quickly.\n",
        "\n",
        "3. Linear Regression:\n",
        "\n",
        "•\tSuitability: Not recommended for binary classification tasks like churn prediction. Designed for continuous outcomes, leading to inappropriate predictions and interpretations in this context.\n",
        "•\tPerformance: Typically poor for churn, as it does not handle the binary nature of the target variable well.\n",
        "•\tInterpretability & Business Relevance: Misleading in a churn scenario; not suitable for actionable insights.\n",
        "\n",
        "Overall Recommendation:\n",
        "\n",
        "For predicting customer churn:\n",
        "\n",
        "\t1.\tLogistic Regression is the best choice if the focus is on actionable insights and straightforward interpretability. It strikes a good balance between performance and usability for business decisions.\n",
        "\t2.\tGAMs can be considered if the data suggests complex patterns that Logistic Regression cannot capture. This approach can provide deeper insights but may require more sophisticated interpretation.\n",
        "\t3.\tLinear Regression should be avoided for this task due to its unsuitability for binary outcomes."
      ],
      "metadata": {
        "id": "yVAJ9YhYVScQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5l983pJQ7hg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}